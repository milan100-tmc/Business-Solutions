# Azure + Microsoft Fabric Scalable E-commerce Customer 360 (Medallion Architecture)

End-to-end, scalable data engineering pipeline built using **Azure ADLS Gen2 + Microsoft Fabric** to deliver Customer 360 analytics** with **Bronze/Silver/Gold** layers and Power BI reporting.

---

## ðŸ”§ Tech Stack (Tools)

### Azure
- **Azure Data Lake Storage Gen2 (ADLS)** â€“ raw landing zone for source files

### Microsoft Fabric
- Workspace â€“ project environment
- OneLake â€“ unified storage layer
- Lakehouse â€“ Bronze/Silver/Gold data organization
- Data Pipelines â€“ ingestion/orchestration from ADLS â†’ Fabric
- Notebooks (PySpark) â€“ transformations and data quality
- Delta Tables â€“ curated Silver/Gold datasets (ACID, performance)
- Power BI â€“ semantic model + dashboards on Gold layer

### Data Formats / Processing
- Parquet** â€“ efficient columnar file format for ingestion
- Delta Lake** â€“ reliable table format for incremental processing
- PySpark** â€“ scalable distributed compute for cleaning & transformation

---

##  Architecture Overview

**ADLS (Raw Source) â†’ Fabric Data Pipeline â†’ Lakehouse (Bronze) â†’ PySpark (Silver) â†’ Gold (Star Schema) â†’ Power BI

### Medallion Layers
- **Bronze: raw ingested data (stored as files in Lakehouse)
- **Silver: cleaned/validated data stored as **Delta tables**
- **Gold: business-ready **facts & dimensions** (Customer 360) stored as **Delta tables**

---

## Data Pipeline Flow (Step-by-step)

1. Land raw files in Azure ADLS Gen2**
   - Source datasets stored in containers/folders (raw truth)

2. Ingest ADLS â†’ Fabric Lakehouse Bronze
   - Fabric Data Pipeline** loads files into Lakehouse Files/Bronze**
   - Uses metadata-driven pattern (Get Metadata + ForEach) for scalability

3. Transform Bronze â†’ Silver with PySpark
   - Type casting, deduplication, null handling, business rule validation
   - Writes curated outputs as **Silver Delta tables**

4. Model Silver â†’ Gold (Customer 360)
   - Creates star-schema tables (facts/dimensions)
   - Stores as **Gold Delta tables** for fast analytics

5. Build Power BI Report
   - Semantic model and measures on Gold tables
   - Dashboards for Customer 360 KPIs


##  Key Design Decisions

### Why Parquet for ingestion?
- Columnar format, compressed, faster reads than CSV
- Efficient for moving raw data from ADLS into Fabric

### Why Delta tables for Silver/Gold?
- **ACID transactions** (reliable updates)
- Better performance with optimizations
- Supports incremental processing patterns and time travel

### Why PySpark?
- Distributed compute for large datasets
- Flexible transformations and data quality enforcement

---

## Output (What you get)
- Cleaned and validated Silver tables
- Business-ready **Gold Customer 360 model
- Power BI dashboards built directly from Gold


